{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffreyong15/Counsel.NLP/blob/main/Llama_RAG(new).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8OSwBlfoqDS"
      },
      "source": [
        "#### INSTALLATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dFo9cOQbhEa"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQBRtKZaUQti"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMyvUAfGMVPK"
      },
      "outputs": [],
      "source": [
        "%pip install datasets langchain-huggingface langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKvizbIjTRG4"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface-hub transformers langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZJc342GV1FN"
      },
      "outputs": [],
      "source": [
        "!pip install pandas==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAxxmuzDZg23"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \"langchain[mistralai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjU7-h50ISMN"
      },
      "outputs": [],
      "source": [
        "!pip install -q rouge_score\n",
        "!pip install -q bert-score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-XBVd1uoxDs"
      },
      "source": [
        "#### FILE IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbX76FizLMXF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import sys\n",
        "import warnings\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import hub\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "from langchain.schema import Document\n",
        "from huggingface_hub import notebook_login\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import spacy\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from bert_score import score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from transformers import logging as transformers_logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnfXNvQlI8qK"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('all', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUIddN4sXDXm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrSzV5fISE5d"
      },
      "outputs": [],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srQvEewvXLln"
      },
      "source": [
        "#### LOAD JSON FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUvlj15NDqTX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myviePI-XHwc"
      },
      "outputs": [],
      "source": [
        "def load_json_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        json_data = json.load(file)\n",
        "\n",
        "    if not json_data:\n",
        "        raise ValueError(\"JSON data is empty\")\n",
        "\n",
        "    print(f\"Successfully loaded {len(json_data)} courses\")\n",
        "    return json_data\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/CMPE-295A/dataset/SJSU_courses_with_metadata_updated.json\"\n",
        "gen_path = \"/content/drive/MyDrive/CMPE-295A/dataset/complete_Gen_Advising.json\"\n",
        "SJSU_dataset = load_json_data(dataset_path)\n",
        "Gen_Advising_Dataset = load_json_data(gen_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qhc6twWURhQ"
      },
      "source": [
        "#### PREPARE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWP0hisIYhwp"
      },
      "outputs": [],
      "source": [
        "# Process dataset (Courses & Majors)\n",
        "class_mapping = {}\n",
        "code = [\"No prerequisites listed\", \"No corequisites listed\"]\n",
        "majors = []\n",
        "category = []\n",
        "def process_data(json_data, gen_data):\n",
        "    documents = []\n",
        "    for item in gen_data:\n",
        "        content = [\n",
        "            f\"Title: {item.get('title', 'N/A')}\",\n",
        "            f\"Description: {item.get('description', 'N/A')}\"\n",
        "        ]\n",
        "        doc = Document(\n",
        "            page_content=\"\\n\".join(content),\n",
        "            metadata={\"title\": item.get('title', 'N/A')}\n",
        "        )\n",
        "        documents.append(doc)\n",
        "\n",
        "\n",
        "    for item in json_data:\n",
        "        majors.append(item['metadata']['major']) if item['metadata']['major'] not in majors else None\n",
        "        if item['id'].isdigit():\n",
        "            category.append(item['metadata']['category']) if item['metadata']['category'] not in category else None\n",
        "        title = item.get('title', 'N/A')\n",
        "        if title != \"N/A\":\n",
        "            class_name = title.split(\"-\")[0].strip()\n",
        "            code.append(class_name)\n",
        "            class_mapping[class_name] = title\n",
        "        content = [\n",
        "            f\"Title: {item.get('title', 'N/A')}\",\n",
        "            f\"Type: {'Major' if 'core_courses' in item else 'Course'}\",\n",
        "            f\"Units: {item.get('units', 'N/A')}\",\n",
        "            f\"Description: {item.get('description', 'N/A')}\",\n",
        "            f\"Grading: {item.get('grading', 'N/A')}\",\n",
        "            f\"Class Structure: {item.get('class_structure', 'Class structure not found')}\"\n",
        "        ]\n",
        "\n",
        "        # Handle prerequisites & corequisites\n",
        "        if item.get('prerequisite(s)'):\n",
        "            content.append(\"Prerequisite(s): \" + \", \".join(item['prerequisite(s)']))\n",
        "\n",
        "        if item.get('corequisite(s)'):\n",
        "            content.append(\"Corequisite(s): \" + \", \".join(item['corequisite(s)']))\n",
        "\n",
        "        if item.get('pre/corequisite(s)'):\n",
        "            content.append(\"Pre/Corequisite(s): \" + \", \".join(item['pre/corequisite(s)']))\n",
        "\n",
        "        if item.get('notes'):\n",
        "            content.append(\"Note(s): \" + \", \".join(item['notes']))\n",
        "\n",
        "        # Handle core courses\n",
        "        if 'core_courses' in item:\n",
        "            content.append(\"\\nCore Courses:\")\n",
        "            for course in item.get('core_courses', []):\n",
        "                content.append(f\"- {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "\n",
        "        # Handle specialization tracks\n",
        "        if 'specialization_tracks' in item:\n",
        "            content.append(\"\\nSpecialization Tracks:\")\n",
        "\n",
        "            for specialization, details in item['specialization_tracks'].items():\n",
        "                content.append(f\"\\n- {specialization}:\")\n",
        "\n",
        "                if isinstance(details, list):  # MSAI-style specialization (direct list of courses)\n",
        "                    for course in details:\n",
        "                        content.append(f\"  - {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "\n",
        "                elif isinstance(details, dict):  # MSSE-style specialization (nested dictionary)\n",
        "                    if 'overview' in details:\n",
        "                        content.append(f\"  Overview: {details['overview']}\")\n",
        "\n",
        "                    if 'required_core_courses' in details:\n",
        "                        content.append(\"\\n  Required Core Courses:\")\n",
        "                        for course in details['required_core_courses']:\n",
        "                            content.append(f\"    - {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "\n",
        "                    if 'specialization_choice_courses' in details:\n",
        "                        content.append(\"\\n  Specialization Choice Courses:\")\n",
        "                        for course in details['specialization_choice_courses']:\n",
        "                            content.append(f\"    - {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "\n",
        "        # Handle elective courses\n",
        "        if 'elective_courses' in item:\n",
        "            content.append(\"\\nElective Courses:\")\n",
        "            if 'overview' in item['elective_courses']:\n",
        "                content.append(f\"  Overview: {item['elective_courses']['overview']}\")\n",
        "                if 'restricted_courses' in item['elective_courses']:\n",
        "                    content.append(\"\\n  Restricted Courses (cannot be taken as electives):\")\n",
        "                    for course in item['elective_courses']['restricted_courses']:\n",
        "                        if isinstance(course, dict):\n",
        "                            content.append(f\"    - {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "                        elif isinstance(course, str):\n",
        "                            content.append(f\"    - {course}\")\n",
        "            else:\n",
        "                for area, courses in item['elective_courses'].items():\n",
        "                    content.append(f\"\\n- {area}:\")\n",
        "                    for course in courses:\n",
        "                        if isinstance(course, dict):\n",
        "                            content.append(f\"  - {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "                        elif isinstance(course, str):\n",
        "                            content.append(f\"  - {course}\")\n",
        "\n",
        "        # Handle graduate writing requirement\n",
        "        if 'graduate_writing_requirement' in item:\n",
        "            content.append(\"\\nGraduate Writing Requirement:\")\n",
        "            gww = item['graduate_writing_requirement']\n",
        "            if 'courses' in gww:  # Multi-course format\n",
        "                for course in gww['courses']:\n",
        "                    content.append(f\"  - {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "                    if 'description' in course:\n",
        "                        content.append(f\"    Description: {course['description']}\")\n",
        "            elif 'course' in gww:  # Single-course format\n",
        "                content.append(f\"  - {gww['course']}: {gww['title']} ({gww['units']} units)\")\n",
        "\n",
        "        # Handle culminating experience\n",
        "        if 'culminating_experience' in item:\n",
        "            content.append(\"\\nCulminating Experience Options:\")\n",
        "            for option, courses in item['culminating_experience'].items():\n",
        "                content.append(f\"\\n- {option}:\")\n",
        "                for course in courses:\n",
        "                    if isinstance(course, dict):\n",
        "                        content.append(f\"  - {course['course']}: {course['title']} ({course['units']} units)\")\n",
        "                    elif isinstance(course, str):\n",
        "                        content.append(f\"  - {course}\")\n",
        "\n",
        "\n",
        "        doc = Document(\n",
        "        page_content=\"\\n\".join(content),\n",
        "        metadata={\"title\": item.get('title', 'N/A'),\n",
        "                  \"class_name\": class_name if item['id'].isdigit() else 'N/A',\n",
        "                  \"type\": \"Major\" if 'core_courses' in item else \"Course\",\n",
        "                  \"major\": item['metadata']['major'],\n",
        "                  \"category\": item['metadata']['category'] if item['id'].isdigit() else 'N/A',\n",
        "                  \"prereq\": item.get(\"prerequisite(s)\", \"N/A\")[0],\n",
        "                  \"coreq\": item.get(\"corequisite(s)\", \"N/A\")[0]}\n",
        "    )\n",
        "        documents.append(doc)\n",
        "\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSHimdVJvuU0"
      },
      "outputs": [],
      "source": [
        "documents = process_data(SJSU_dataset, Gen_Advising_Dataset)\n",
        "for d in documents:\n",
        "  if len(d.metadata) > 1:\n",
        "    p = d.metadata[\"prereq\"]\n",
        "    co = d.metadata[\"coreq\"]\n",
        "    prereq = []\n",
        "    i = 1\n",
        "    j = 1\n",
        "    for c in code:\n",
        "      if c in p:\n",
        "        d.metadata[f\"prereq_{i}\"] = c\n",
        "        i += 1\n",
        "      if c in co:\n",
        "        d.metadata[f\"coreq_{j}\"] = c\n",
        "        j += 1\n",
        "    if i == 1:\n",
        "      d.metadata[f\"prereq_{i}\"] = \"N/A\"\n",
        "    if j == 1:\n",
        "      d.metadata[f\"coreq_{j}\"] = \"N/A\"\n",
        "    del d.metadata['prereq']\n",
        "    del d.metadata['coreq']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31thxI0V_rX7"
      },
      "outputs": [],
      "source": [
        "code = code[:-3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_YkLYIicbmD"
      },
      "outputs": [],
      "source": [
        "documents[800].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qp0SyomUXfL"
      },
      "source": [
        "#### VECTOR STORE SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSyUtkKef3vn"
      },
      "outputs": [],
      "source": [
        "directory = \"./vector__store\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
        "vector_store = Chroma.from_documents(documents=documents, embedding=embeddings, persist_directory=directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFFlJC5jgpHJ"
      },
      "outputs": [],
      "source": [
        "vector_store.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qim7V5jywUkg"
      },
      "outputs": [],
      "source": [
        "vector_store.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8fV1tYfUhUE"
      },
      "source": [
        "#### VECTOR STORE LOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26QTD7QKsff6"
      },
      "outputs": [],
      "source": [
        "# LOAD WITH THIS\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
        "directory = \"/content/drive/MyDrive/CMPE-295A/dataset/vector__store\"\n",
        "vector_store = Chroma(persist_directory=directory, embedding_function=embeddings)\n",
        "vector_store.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El3WVeBMs2eS"
      },
      "outputs": [],
      "source": [
        "# $gt, $gte, $lt, $lte, $ne, $eq, $in, $nin\n",
        "results = vector_store.similarity_search(\n",
        "    \"What courses require MATH 32 as a prerequisite?\",\n",
        "    k=5,\n",
        "    filter={\"$or\": [{\"$and\": [{\"prereq_1\": {\"$eq\": \"BIOL 115\"}},\n",
        "                    {\"prereq_2\": {\"$eq\": \"BIOL 118\"}}]},\n",
        "                    {\"$and\": [{\"prereq_1\": {\"$eq\": \"BIOL 118\"}},\n",
        "                    {\"prereq_2\": {\"$eq\": \"BIOL 115\"}}]}]}\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "homfAWkEWm5i"
      },
      "source": [
        "#### MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pyvco48WoK4"
      },
      "outputs": [],
      "source": [
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# Llama_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "\n",
        "# llm = HuggingFaceEndpoint(repo_id=Llama_model,\n",
        "#                             task=\"text-generation\",\n",
        "#                             max_new_tokens=512,\n",
        "#                             do_sample=False,\n",
        "#                             repetition_penalty=1.03)\n",
        "\n",
        "Llama_model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=Llama_model,\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=256,\n",
        "    do_sample=False,\n",
        "    temperature=0.4,\n",
        "    repetition_penalty=1.03\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7lD9IeRUuak"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/CMPE-295A/dataset/courses.txt\"\n",
        "with open(file_path, \"r\") as f:\n",
        "  courses = f.read().splitlines()\n",
        "courses.remove('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB8QQISbibWS"
      },
      "outputs": [],
      "source": [
        "def classify_question(question: str):\n",
        "  if \"between\" in question:\n",
        "    filters = []\n",
        "    for c in courses:\n",
        "      if c in question:\n",
        "        filters.append({\"class_name\":{\"$eq\": c}})\n",
        "    filter = {\"$or\": filters}\n",
        "    return filter if len(filters) != 0 else None\n",
        "  elif \"require\" in question or \"have\" in question:\n",
        "    if \"corequisite\" in question and \"prerequisite\" in question:\n",
        "      coreq_pos = question.find(\"corequisite\")\n",
        "      prereq_pos = question.find(\"prerequisite\")\n",
        "      filters = []\n",
        "      if coreq_pos < prereq_pos:\n",
        "        sec_1 = question[:coreq_pos]\n",
        "        sec_2 = question[coreq_pos:]\n",
        "        i = 1\n",
        "        j = 1\n",
        "        for c in courses:\n",
        "          if c in sec_1:\n",
        "            filters.append({f\"coreq_{i}\": {\"$eq\": c}})\n",
        "            i += 1\n",
        "          if c in sec_2:\n",
        "            filters.append({f\"prereq_{j}\": {\"$eq\": c}})\n",
        "            j += 1\n",
        "        filter = {\"$and\": filters} if \"and\" in question else {\"$or\": filters}\n",
        "        if len(filters) < 2:\n",
        "          filter = filters\n",
        "        return filter[0] if len(filters) != 0 else None\n",
        "      else:\n",
        "        sec_1 = question[:prereq_pos]\n",
        "        sec_2 = question[prereq_pos:]\n",
        "        for c in courses:\n",
        "          i = 1\n",
        "          j = 1\n",
        "          if c in sec_1:\n",
        "            filters.append({f\"prereq_{i}\": {\"$eq\": c}})\n",
        "            i += 1\n",
        "          if c in sec_2:\n",
        "            filters.append({f\"coreq_{j}\": {\"$eq\": c}})\n",
        "            j += 1\n",
        "        filter = {\"$and\": filters} if \"and\" in question else {\"$or\": filters}\n",
        "        if len(filters) < 2:\n",
        "          filter = filters\n",
        "        return filter[0] if len(filters) != 0 else None\n",
        "\n",
        "    # PREREQ\n",
        "    elif \"prerequisite\" in question:\n",
        "      # Require multiple prerequisites\n",
        "        filters = []\n",
        "        i = 1\n",
        "        for c in courses:\n",
        "          if c in question:\n",
        "            filters.append({f\"prereq_{i}\": {\"$eq\": c}})\n",
        "            i += 1\n",
        "        filter = {\"$and\": filters} if \"and\" in question else {\"$or\": filters}\n",
        "        if len(filters) < 2:\n",
        "          filter = filters\n",
        "        return filter[0] if len(filters) != 0 else None\n",
        "    else:\n",
        "      filters = []\n",
        "      i = 1\n",
        "      for c in courses:\n",
        "        if c in question:\n",
        "          filters.append({f\"coreq_{i}\": {\"$eq\": c}})\n",
        "          i += 1\n",
        "      filter = {\"$and\": filters} if \"and\" in question else {\"$or\": filters}\n",
        "      if len(filters) < 2:\n",
        "        filter = filters\n",
        "      return filter[0] if len(filters) !=0 else None\n",
        "  elif \"need\" in question:\n",
        "    last_course = \"\"\n",
        "    for c in courses:\n",
        "      if c in question:\n",
        "        if question.find(last_course) < question.find(c):\n",
        "          last_course = c\n",
        "    return {\"class_name\": last_course}\n",
        "  else:\n",
        "    #FIND THE CLASS\n",
        "    for c in courses:\n",
        "      if c in question:\n",
        "        return {\"class_name\": c}\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMtGVakb0CMH"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "Answer the question based on the context below.\n",
        "Do not make up information. Be concise and to the point.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "    source_documents: List[str]\n",
        "\n",
        "def retrieve(state: State) -> State:\n",
        "    filter = classify_question(state[\"question\"])\n",
        "    retrieved_docs = vector_store.similarity_search(\n",
        "        state[\"question\"],\n",
        "        k=10,\n",
        "        filter=filter\n",
        "    )\n",
        "    # Extract source document content\n",
        "    source_documents = [doc.page_content for doc in retrieved_docs]\n",
        "    return {\"context\": retrieved_docs, \"source_documents\": source_documents}\n",
        "\n",
        "# def generate(state: State) -> State:\n",
        "#     docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "#     messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "#     response = llm.invoke(messages)\n",
        "#     return {\"answer\": response, \"source_documents\": state[\"source_documents\"]}\n",
        "\n",
        "def generate(state: State) -> State:\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt_template.format(context=docs_content, question=state[\"question\"])\n",
        "    response = llm.invoke(messages)\n",
        "\n",
        "    # Remove excessive spaces and line breaks\n",
        "    response = response.replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
        "\n",
        "    # Remove unwanted phrases\n",
        "    response = re.sub(r\"\\bI don't know\\b|\\bAdditionally\\b|\\bIn conclusion\\b|\\bbased on the context\\b\", \"\", response).strip()\n",
        "\n",
        "    # Remove list artifacts like \"\\t+\" or \"\\t\"\n",
        "    response = re.sub(r\"\\t\\+|\\t\", \"\", response)\n",
        "\n",
        "    return {\"answer\": response, \"source_documents\": state[\"source_documents\"]}\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5YXmy956gwi"
      },
      "outputs": [],
      "source": [
        "questions = [\"What are the prerequisites for KIN 1?\",\n",
        "        \"List all the different CMPE courses.\",\n",
        "        \"What are the core courses for the MSAI major?\",\n",
        "        \"Can you provide the description of CMPE 252?\",\n",
        "        \"What are the restricted courses for MSSE major as an elective course?\",\n",
        "        \"What are specialization tracks for MSAI major?\",\n",
        "        \"What are the prerequisites for CS 156?\",\n",
        "        \"What are the corequisites for BIOL 124?\",\n",
        "        \"What are the pre/corequisites for ARTH 11?\",\n",
        "        \"What is the class structure for AE 110?\",\n",
        "        \"What are the prerequisites for the MSCMPE major?\",\n",
        "        \"What are all the elective courses for the MSAI major?\",\n",
        "        \"What are the culminating experience options for the MSSE major?\",\n",
        "        \"What are the graduate writing requirement for the MSSE major?\",\n",
        "        \"What courses require CMPE 252 as a prerequisite?\",\n",
        "        \"Which KIN courses fulfill Movement Area 5 Team requirements?\",\n",
        "        \"How many units is ISE 297?\",\n",
        "        \"Is there a beginning-level swimming course at SJSU?\",\n",
        "        \"Do I need instructor consent to enroll in ADV 116 - Spartan Daily Advertising Staff?\",\n",
        "        \"Do I need MATH 33A to enroll in AE 105 - Mathematical Methods for Aerospace Engineers?\",\n",
        "        \"Can I take ADV 127 - Practical Qualitative Research in Advertising without taking ADV 91?\",\n",
        "        \"What is the grading system for CHIN 132?\",\n",
        "        \"What are the course recommendations for Software Engineering(MSSE) major?\",\n",
        "        \"What are the best courses to take for machine learning?\",\n",
        "        \"Can you recommend an advertising course that focuses on digital media?\",\n",
        "        \"I want to take a dance class. What are my options?\",\n",
        "        \"What are the core courses for Software Engineering(MSSE) major?\",\n",
        "        \"Which aerospace courses involve MATLAB programming?\",\n",
        "        \"What is the difference between KIN 35A and KIN 35B?\",\n",
        "        \"What are the prerequisites for BUS4 119A?\",\n",
        "        \"How many units should i complete as a software engineer major at SJSU?\",\n",
        "        \"Are there any Software Engineering courses that focus specifically on cloud computing and distributed systems?\",\n",
        "        \"What are the necessary prerequisites for taking What are the necessary prerequisites for taking Introduction to Database Management Systems (CS 157A)?\",\n",
        "        \"If I want to take CS 160, which courses should I complete first?\",\n",
        "        \"If I want to focus on cybersecurity, can I substitute any SE courses for CS security-related electives?\",\n",
        "        \"Can a Software Engineering major take AI-focused courses from the CS department as electives?\",\n",
        "        \"What are the best elective choices for a CS student who wants to specialize in data science?\",\n",
        "        \"How can a graduate student clear their provisional admission status?\",\n",
        "        \"Are graduate students allowed to leave for a semester?\",\n",
        "        \"Are undergraduate courses considered in GPA calculation for graduates?\",\n",
        "        \"How do I switch to a different graduate program?\",\n",
        "        \"Can I enroll in two masters program at the same time?\",\n",
        "        \"What resources are available for graduate students through the SJSU Writing Center?\",\n",
        "        \"Are there organizations to connect with Alumni?\",\n",
        "        \"What should graduate students do if they need to change their graduation date?\",\n",
        "        \"How do I maintain my F-1 Status?\",\n",
        "        \"What are the requirements for the J-1 visitor program?\",\n",
        "        \"What grades are considered unsatisfactory?\",\n",
        "        \"What grades are condidered satisfactory?\",\n",
        "        \"What is the deadline for submitting my candidacy form?\",\n",
        "        \"How do I negotiate an offer with my employer?\",\n",
        "        \"What are some interview tips?\",\n",
        "        \"What type of questions are asked in interviews?\",\n",
        "        \"What opportunities are there for graudate students?\",\n",
        "        \"What should I do after accepted a job offer?\",\n",
        "        \"How should I format my resume as an international?\",\n",
        "        \"What are some tips to maximize my experience at a career fair?\",\n",
        "        \"How important is it to network?\",\n",
        "        \"Who can I talk to about financial aid related information?\",\n",
        "        \"Does SJSU have any counseling services?\",\n",
        "        \"What are some common interview questions?\"\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQMYbu2YOQrY"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "question_id = []\n",
        "question = []\n",
        "responses = []\n",
        "source_docs = []\n",
        "response_times = []\n",
        "response_lengths = []\n",
        "\n",
        "for idx, q in enumerate(questions, start=1):\n",
        "    print(q)\n",
        "    question_id.append(idx)\n",
        "    question.append(q)\n",
        "    start_time = time.time()\n",
        "    response = graph.invoke({\"question\": q})\n",
        "    elapsed_time = time.time() - start_time\n",
        "    answer_length = len(response[\"answer\"])\n",
        "\n",
        "    responses.append(response[\"answer\"])\n",
        "    source_docs.append(response[\"source_documents\"])\n",
        "    response_times.append(round(elapsed_time, 2))\n",
        "    response_lengths.append(answer_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvxlLycF8Ioy"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    \"Question_id\": question_id,\n",
        "    \"Questions\": question,\n",
        "    \"Responses\": responses,\n",
        "    \"Source_Documents\": source_docs,\n",
        "    \"Response_Time\": response_times,\n",
        "    \"Response_Length\": response_lengths\n",
        "})\n",
        "\n",
        "responses_df = df.drop(columns=[col for col in df.columns if 'Source_Documents' in col or col == 'Question_id'])\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df.to_csv(\"answers.csv\", index=False)\n",
        "responses_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHbIwxz2mAqZ"
      },
      "source": [
        "#### EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMH-OaAHdjrV"
      },
      "outputs": [],
      "source": [
        "# def calculate_rouge_scores(prediction: str, reference: str) -> dict:\n",
        "#     scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "#     scores = scorer.score(reference, prediction)\n",
        "#     return {\n",
        "#         'rouge1': scores['rouge1'].fmeasure,\n",
        "#         'rouge2': scores['rouge2'].fmeasure,\n",
        "#         'rougeL': scores['rougeL'].fmeasure\n",
        "#     }\n",
        "\n",
        "# def calculate_bleu_score(prediction: str, reference: str) -> float:\n",
        "#     smoother = SmoothingFunction()\n",
        "#     prediction_tokens = word_tokenize(prediction.lower())\n",
        "#     reference_tokens = [word_tokenize(reference.lower())]\n",
        "#     return sentence_bleu(reference_tokens, prediction_tokens, smoothing_function=smoother.method1)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def calculate_bertscore(prediction: str, reference: str):\n",
        "    P, R, F1 = score([prediction], [reference], lang=\"en\", verbose=False)\n",
        "    return F1.mean().item()\n",
        "\n",
        "def check_answer_presence(prediction: str, source_docs: list) -> float:\n",
        "    stopwords_set = set(STOP_WORDS)\n",
        "\n",
        "    pred_doc = nlp(prediction)\n",
        "    source_text = ' '.join(source_docs) if source_docs else ''\n",
        "    source_doc = nlp(source_text)\n",
        "\n",
        "    pred_elements = set()\n",
        "    pred_elements.update([ent.text.lower() for ent in pred_doc.ents])\n",
        "    pred_elements.update([chunk.text.lower() for chunk in pred_doc.noun_chunks])\n",
        "\n",
        "    if not pred_elements:\n",
        "        return 1.0\n",
        "\n",
        "    matches = 0\n",
        "    for element in pred_elements:\n",
        "        if element in source_text.lower() and element not in stopwords_set:\n",
        "            matches += 1\n",
        "\n",
        "    return matches / len(pred_elements)\n",
        "\n",
        "def check_consistency(prediction: str, source_docs: list) -> float:\n",
        "    stopwords_set = set(STOP_WORDS)\n",
        "\n",
        "    pred_doc = nlp(prediction)\n",
        "    source_doc = nlp(' '.join(source_docs)) if source_docs else nlp('')\n",
        "\n",
        "    pred_numbers = [token.text for token in pred_doc if token.like_num and token.text not in stopwords_set]\n",
        "    source_numbers = [token.text for token in source_doc if token.like_num and token.text not in stopwords_set]\n",
        "\n",
        "    if not pred_numbers:\n",
        "        return 1.0\n",
        "\n",
        "    matches = sum(1 for num in pred_numbers if num in source_numbers)\n",
        "    return matches / len(pred_numbers) if pred_numbers else 1.0\n",
        "\n",
        "def evaluate_model(responses_df, reference_dict):\n",
        "    individual_metrics_data = {\n",
        "        'question_id': [],\n",
        "        'bertscore_f1': [],\n",
        "        'answer_presence': [],\n",
        "        'consistency': []\n",
        "    }\n",
        "\n",
        "    all_metrics = {\n",
        "        'bertscore_f1': [],\n",
        "        'answer_presence': [],\n",
        "        'consistency': []\n",
        "    }\n",
        "\n",
        "    for _, row in responses_df.iterrows():\n",
        "        question_id = row['Question_id']\n",
        "        model_response = row['Responses']\n",
        "        source_documents = row['Source_Documents']\n",
        "\n",
        "        reference_answer = reference_dict.get(question_id, \"\")\n",
        "\n",
        "        model_response = model_response if isinstance(model_response, str) else ''\n",
        "        source_documents = ' '.join([doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in source_documents]) if isinstance(source_documents, list) else source_documents\n",
        "\n",
        "        bert_score = calculate_bertscore(model_response, reference_answer)\n",
        "        answer_presence = check_answer_presence(model_response, [source_documents])\n",
        "        consistency = check_consistency(model_response, [source_documents])\n",
        "\n",
        "        individual_metrics_data['question_id'].append(question_id)\n",
        "        individual_metrics_data['bertscore_f1'].append(bert_score)\n",
        "        individual_metrics_data['answer_presence'].append(answer_presence)\n",
        "        individual_metrics_data['consistency'].append(consistency)\n",
        "\n",
        "        all_metrics['bertscore_f1'].append(bert_score)\n",
        "        all_metrics['answer_presence'].append(answer_presence)\n",
        "        all_metrics['consistency'].append(consistency)\n",
        "\n",
        "    average_metrics = {\n",
        "        'bertscore_f1': sum(all_metrics['bertscore_f1']) / len(all_metrics['bertscore_f1']),\n",
        "        'answer_presence': sum(all_metrics['answer_presence']) / len(all_metrics['answer_presence']),\n",
        "        'consistency': sum(all_metrics['consistency']) / len(all_metrics['consistency'])\n",
        "    }\n",
        "\n",
        "    # Create DataFrames\n",
        "    individual_metrics_df = pd.DataFrame(individual_metrics_data)\n",
        "    average_metrics_df = pd.DataFrame([average_metrics])\n",
        "\n",
        "    return individual_metrics_df, average_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE6WxPpWkbWu"
      },
      "outputs": [],
      "source": [
        "# Disable transformers warnings\n",
        "transformers_logging.set_verbosity_error()\n",
        "\n",
        "reference_path = \"/content/drive/MyDrive/CMPE-295A/dataset/SJSU_reference_answer.json\"\n",
        "with open(reference_path, 'r') as file:\n",
        "    reference_data = json.load(file)\n",
        "\n",
        "reference_ans = {item['question_id']: item['reference_answer'] for item in reference_data}\n",
        "\n",
        "individual_metrics_df, average_metrics_df = evaluate_model(df, reference_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6RNTC6jnjdF"
      },
      "outputs": [],
      "source": [
        "individual_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVp1E2Gpnntb"
      },
      "outputs": [],
      "source": [
        "average_metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gazc2VyLnYE"
      },
      "source": [
        "#### VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeWc9_StMO1D"
      },
      "outputs": [],
      "source": [
        "# Melt the DataFrame for easier plotting\n",
        "df_melted = individual_metrics_df.melt(id_vars=['question_id'],\n",
        "                    value_vars=['bertscore_f1', 'answer_presence', 'consistency'],\n",
        "                    var_name='metric',\n",
        "                    value_name='score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVjTxQGsMTW6"
      },
      "outputs": [],
      "source": [
        "# Plot for BERTScore\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='question_id', y='score', data=df_melted[df_melted['metric'] == 'bertscore_f1'],\n",
        "            ci=None, palette=\"spring\")\n",
        "\n",
        "plt.title('BERTScore Comparison', fontsize=13)\n",
        "plt.xlabel('Question ID', fontsize=11)\n",
        "plt.ylabel('BERTScore F1', fontsize=11)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trXrbRPfNh5W"
      },
      "outputs": [],
      "source": [
        "# Plot for Answer Presence\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='question_id', y='score', data=df_melted[df_melted['metric'] == 'answer_presence'],\n",
        "            ci=None, palette=\"magma\")\n",
        "\n",
        "plt.title('Answer Presence Comparison', fontsize=13)\n",
        "plt.xlabel('Question ID', fontsize=11)\n",
        "plt.ylabel('Answer Presence', fontsize=11)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "volNbry7NmxH"
      },
      "outputs": [],
      "source": [
        "# Plot for Consistency\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='question_id', y='score', data=df_melted[df_melted['metric'] == 'consistency'],\n",
        "            ci=None, palette=\"YlGnBu\")\n",
        "\n",
        "plt.title('Consistency Comparison', fontsize=13)\n",
        "plt.xlabel('Question ID', fontsize=11)\n",
        "plt.ylabel('Consistency', fontsize=11)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYuacjxRqAi0"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(individual_df):\n",
        "    mean_metrics = individual_df[['bertscore_f1', 'answer_presence', 'consistency']].mean()\n",
        "\n",
        "    ax = mean_metrics.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'lightgreen', 'salmon'])\n",
        "\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{p.get_height():.4f}',\n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                    ha='center', va='center', fontsize=12, color='black',\n",
        "                    xytext=(0, 5), textcoords='offset points')\n",
        "\n",
        "    plt.title(\"Average Performance of the Model Across Metrics\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.xlabel(\"Metric\")\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def summary_statistics(individual_df):\n",
        "    summary = individual_df[['bertscore_f1', 'answer_presence', 'consistency']].agg(['mean', 'std'])\n",
        "    print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWguNUokLflP"
      },
      "outputs": [],
      "source": [
        "plot_metrics(individual_metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO_on5ouLceQ"
      },
      "outputs": [],
      "source": [
        "summary_statistics(individual_metrics_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-8OSwBlfoqDS",
        "srQvEewvXLln",
        "2qhc6twWURhQ",
        "3qp0SyomUXfL"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}